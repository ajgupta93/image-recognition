{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('./tinyshakespeare.txt').read()\n",
    "text_len = len(text)\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk(chunk_len=100):\n",
    "    start_index = random.randint(0, text_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "def to_tensor(string, dtype='float'):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "def random_training_set():    \n",
    "    chunk = get_chunk()\n",
    "    inp = to_tensor(chunk[:-1])\n",
    "    target = to_tensor(chunk[1:])\n",
    "    inp.cuda()\n",
    "    target.cuda()\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, htype='rnn', lr=0.005):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.htype = htype\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        print(htype)\n",
    "        if htype=='rnn':\n",
    "            self.model = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        elif htype=='lstm':\n",
    "            self.model = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        elif htype=='gru':\n",
    "            self.model = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.model(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def evaluate(self, prime_str='T', predict_len=500, temperature=0.8):\n",
    "        hidden = self.init_hidden()\n",
    "        prime_input = to_tensor(prime_str)\n",
    "        predicted = prime_str\n",
    "        \n",
    "        if cuda:\n",
    "            hidden = hidden.cuda()\n",
    "            prime_input = prime_input.cuda()\n",
    "\n",
    "        # Use priming string to \"build up\" hidden state\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            _, hidden = self(prime_input[p], hidden)\n",
    "        inp = prime_input[-1]\n",
    "\n",
    "        for p in range(predict_len):\n",
    "            output, hidden = self(inp, hidden)\n",
    "\n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_char = all_characters[top_i]\n",
    "            predicted += predicted_char\n",
    "            inp = to_tensor(predicted_char)\n",
    "            if cuda:\n",
    "                inp = inp.cuda()\n",
    "\n",
    "        return predicted\n",
    "    \n",
    "    def train(self, inp, target, chunk_len=100):\n",
    "        hidden = self.init_hidden()\n",
    "        hidden.cuda()\n",
    "        self.zero_grad()\n",
    "        loss = 0\n",
    "\n",
    "        for c in range(chunk_len):\n",
    "            output, hidden = self(inp[c], hidden)\n",
    "            loss += self.criterion(output, target[c])\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.data[0]/chunk_len\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.htype == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, 1, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, 1, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size),\\\n",
    "                        requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn\n",
      "Model(\n",
      "  (encoder): Embedding(100, 100)\n",
      "  (model): RNN(100, 100)\n",
      "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (criterion): CrossEntropyLoss(\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_rnn = Model(n_characters, hidden_size, n_characters, n_layers=2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100 5%) 2.4045]\n",
      "Whin, wat hall tim wis meand hou le. sha\n",
      "At ig d toEd ol thou, torhid ueg mat om te, touprowhand att t\n",
      "\n",
      "\n",
      "[(200 10%) 2.6222]\n",
      "Whad soe and nod dus and en, sand pade ing, ay hon and pid, rony wave\n",
      "Toire, hemy mele mid! sour.\n",
      "\n",
      "AfA\n",
      "\n",
      "\n",
      "[(300 15%) 2.3643]\n",
      "Whing je attant mreang the hext not fa comt thagh!\n",
      "In unte the nothe sugh, I fats mato thot o tave the\n",
      "\n",
      "\n",
      "[(400 20%) 2.0662]\n",
      "Whentangshat for heme nathis so lonfed theld youphat and hatind for sinls: thold is:\n",
      "Heven yat of poth\n",
      "\n",
      "\n",
      "[(500 25%) 1.9115]\n",
      "Who@s I, thet we diof yough prow lay to of hilkho, and tr at fade domy serwice, the shis of int of cor\n",
      "\n",
      "\n",
      "[(600 30%) 2.2830]\n",
      "Whou me then ape and theall dook beif the frak's thour 'ther thech\n",
      "uposbech tho dee pere cords shim\n",
      "Is\n",
      "\n",
      "\n",
      "[(700 35%) 1.8375]\n",
      "Whan is mate?\n",
      "\n",
      "SRING IVINI:\n",
      "Wame whas,\n",
      "Work the me then noss Mato blaye lor prishirs the llarty'ther f\n",
      "\n",
      "\n",
      "[(800 40%) 1.8653]\n",
      "Whall you Buss the prack his inbry be kince prish be with for of that lould hast swort now of thou pos\n",
      "\n",
      "\n",
      "[(900 45%) 2.2946]\n",
      "Why hame mises the stuld reatle so my cold.\n",
      "\n",
      "Paight the of the dy she the the him to\n",
      "O it the not seep\n",
      "\n",
      "\n",
      "[(1000 50%) 2.2975]\n",
      "Whour han to seest is mell have ween for land, that desting have and werd,\n",
      "And by hang thour to for ha\n",
      "\n",
      "\n",
      "[(1100 55%) 2.2043]\n",
      "Whand the whing love me retios dich dead. Shou the wor,\n",
      "Thy then, sues liver:\n",
      "The thingrate now fou wo\n",
      "\n",
      "\n",
      "[(1200 60%) 1.9791]\n",
      "Whanns than the is Misman:\n",
      "Sect.\n",
      "\n",
      "Fivew have dodaned ove mes are wint not all it is sand to out iase m\n",
      "\n",
      "\n",
      "[(1300 65%) 2.1414]\n",
      "What and thou with with your worther, shale\n",
      "And will wert.\n",
      "\n",
      "PETRUCUS:\n",
      "Whe souling other'd a with the d\n",
      "\n",
      "\n",
      "[(1400 70%) 1.9271]\n",
      "Where that granion eve that ol the comer the can finter do puthre in reved:\n",
      "To sodsh;\n",
      "But shall caulpe\n",
      "\n",
      "\n",
      "[(1500 75%) 1.9640]\n",
      "Where to your jomain pee; io he wercurow live of themio, and thich hark's theriole ther's hem.\n",
      "\n",
      "IDIUS:\n",
      "\n",
      "\n",
      "[(1600 80%) 1.6946]\n",
      "Wher! Tirl had mospies to wither entrous do lord, wheren:\n",
      "And his sticlen:\n",
      "O samet not of to with and \n",
      "\n",
      "\n",
      "[(1700 85%) 2.2122]\n",
      "What their met so\n",
      "\n",
      "POLIET:\n",
      "Let the,\n",
      "And him be this my me, you\n",
      "my hungent book, surefray the add have \n",
      "\n",
      "\n",
      "[(1800 90%) 1.9205]\n",
      "Wher of thy,\n",
      "And I suriad loot him contruch ]elut anrey a sesel shall the ellon,\n",
      "Drempost the rounter \n",
      "\n",
      "\n",
      "[(1900 95%) 1.9041]\n",
      "Where 'lear they a betraves.\n",
      "\n",
      "CORICK:\n",
      "Good the come a hathort Yave my goss me.\n",
      "They that my suar are a\n",
      "\n",
      "\n",
      "[(2000 100%) 1.6803]\n",
      "Who heriee\n",
      "! I'ster; and are ward have:\n",
      "Prear of all shall where if pleer hear dearter-mane ome:\n",
      "And i\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = model_rnn.train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % (epoch, 1.*epoch/n_epochs*100, loss))\n",
    "        print(model_rnn.evaluate('Wh', 100))\n",
    "        print('\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wertaming ome! with of and by dost will your detter'--noo stath alver\n",
      "argee.\n",
      "\n",
      "Sou;\n",
      "I cumed;\n",
      "The congely vise prot e fatt he but yow the here tayblest your oor hands whis promer of unhim sod wetter.\n",
      "\n",
      "LADY:\n",
      "Priushes, firrwores! I\n",
      "we vear pargatore a were crom hich to carke not holl am shours;\n",
      "Iy it wherat your spee him not be deeps\n",
      "I shout peard hade to have: and sharo!\n",
      "If yoursessire.\n",
      "\n",
      "LADY OO:\n",
      "wordy yours my and the upon he hever again hear my ly con amer me of thee hery to when a me ate I wall'd \n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate('We', 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru\n",
      "Model(\n",
      "  (encoder): Embedding(100, 100)\n",
      "  (model): GRU(100, 100)\n",
      "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (criterion): CrossEntropyLoss(\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(n_characters, hidden_size, n_characters, n_layers, htype='gru')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100 5%) 2.2694]\n",
      "[(200 10%) 2.0985]\n",
      "[(300 15%) 2.0937]\n",
      "[(400 20%) 2.0440]\n",
      "[(500 25%) 2.2702]\n",
      "[(600 30%) 2.0048]\n",
      "[(700 35%) 2.1530]\n",
      "[(800 40%) 2.1840]\n",
      "[(900 45%) 2.0941]\n",
      "[(1000 50%) 2.1113]\n",
      "[(1100 55%) 1.8443]\n",
      "[(1200 60%) 2.1550]\n",
      "[(1300 65%) 2.1281]\n",
      "[(1400 70%) 1.9685]\n",
      "[(1500 75%) 1.9968]\n",
      "[(1600 80%) 1.8302]\n",
      "[(1700 85%) 1.7155]\n",
      "[(1800 90%) 2.2517]\n",
      "[(1900 95%) 1.7101]\n",
      "[(2000 100%) 1.7692]\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = model.train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % (epoch, 1.*epoch/n_epochs*100, loss))\n",
    "        #print(model.evaluate('Wh', 100))\n",
    "        #print('\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinost\n",
      "O, as leansed cate of love:\n",
      "Good hopbe to sece,\n",
      "Which the to prearviced wet the states ope's\n",
      "To arse a such to timen alb\n",
      "ingre mood you so\n",
      "dake to and ight eed my lond.\n",
      "That Wauce\n",
      "What to love a mood,\n",
      "Le of conte the time take to beveniose and he walf consiford:\n",
      "With the hem the to mad.\n",
      "\n",
      "DUCHESTER:\n",
      "Is batigh than to to to sin to pay we the stard of as grate to mine\n",
      "The m the stade blood\n",
      "The me flousming the searss.\n",
      "\n",
      "Nor Kather:\n",
      "To sayer at stards of gat of to beace ut the hable.\n",
      "\n",
      "CAJUDIO:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate('Ki', 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm\n",
      "Model(\n",
      "  (encoder): Embedding(100, 100)\n",
      "  (model): LSTM(100, 100)\n",
      "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (criterion): CrossEntropyLoss(\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Model(n_characters, hidden_size, n_characters, n_layers, htype='lstm')\n",
    "print(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100 5%) 2.3804]\n",
      "[(200 10%) 2.3588]\n",
      "[(300 15%) 2.4034]\n",
      "[(400 20%) 2.1262]\n",
      "[(500 25%) 2.1673]\n",
      "[(600 30%) 2.0382]\n",
      "[(700 35%) 1.9352]\n",
      "[(800 40%) 1.8142]\n",
      "[(900 45%) 2.1993]\n",
      "[(1000 50%) 2.0887]\n",
      "[(1100 55%) 2.3438]\n",
      "[(1200 60%) 2.0311]\n",
      "[(1300 65%) 2.0284]\n",
      "[(1400 70%) 1.8825]\n",
      "[(1500 75%) 1.6077]\n",
      "[(1600 80%) 2.0182]\n",
      "[(1700 85%) 2.0066]\n",
      "[(1800 90%) 2.0296]\n",
      "[(1900 95%) 1.8115]\n",
      "[(2000 100%) 1.9400]\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = model_lstm.train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % (epoch, 1.*epoch/n_epochs*100, loss))\n",
    "        #print(model.evaluate('Wh', 100))\n",
    "        #print('\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABANGBRUT:\n",
      "You groud 'tis a a trauch head pauding graid for the diefore fance, and with the send and the lauld should and thest that now revam or greed?\n",
      "The cald made this flich think that this houne.\n",
      "\n",
      "Clown:\n",
      "Tage it fring my you stiund,\n",
      "Take to the caumple the caund the cabrockbent, lest the the camaul fathing Kate and me,\n",
      "The you and pardses will I greest stands! Shepprace:\n",
      "The heron mond the she mens I lark and the come, shing hip prock preats, awn and a spather, and derters all make the or me\n"
     ]
    }
   ],
   "source": [
    "print(model_lstm.evaluate('A', 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
